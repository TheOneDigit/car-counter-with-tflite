{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yPNK1_scipz",
        "outputId": "154bb27b-6a2b-42dc-a154-c39980466d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from tensorflow.keras import metrics\n",
        "import tensorflow as tf\n",
        "\n",
        "custom_objects = {\n",
        "    'mse': metrics.MeanSquaredError()\n",
        "}\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/car-object-detection.h5', custom_objects=custom_objects)\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = 'twocars.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "image_orig = image_rgb.copy()  # Keep the original RGB image for visualization\n",
        "\n",
        "# Resize the image for model input\n",
        "image_resized = cv2.resize(image_rgb, (676, 380))  # Resize to the input size required by your model\n",
        "image_resized = image_resized / 255.0  # Normalize if your model expects normalized inputs\n",
        "\n",
        "# Expand dimensions to match model input shape\n",
        "image_resized = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(image_resized)\n",
        "\n",
        "# Extract bounding boxes from predictions\n",
        "for box in predictions:  # Iterate through each bounding box\n",
        "    x1, y1, x2, y2 = box.astype(int)  # Convert coordinates to integers\n",
        "    cv2.rectangle(image_orig, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
        "\n",
        "# Convert back to BGR for OpenCV display\n",
        "image_display = cv2.cvtColor(image_orig, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ny81le9eESw",
        "outputId": "ce8579e1-3183-4de5-f0d0-8c3a293382fe"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "19_MUgGXePK7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ldp2-k7becTZ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WrlTk1G8fsmS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJ_fTYl3iHrP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}